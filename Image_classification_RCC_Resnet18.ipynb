{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMEUqhQgqO8cqFAbZ2tTGo3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/team0243/Project_ML/blob/main/Image_classification_RCC_Resnet18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import PIL"
      ],
      "metadata": {
        "id": "Wk6aCeeZspwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing The Data\n"
      ],
      "metadata": {
        "id": "PiMo2y9saMkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data transformations for data augmentation and normalization\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "JXbKraE4swil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5srOHgH-aP93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data directory\n",
        "data_dir = Path(\"/content/drive/MyDrive/โครงการFF/Resnet-18\")\n",
        "\n",
        "# Create data loaders\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "#image_datasets"
      ],
      "metadata": {
        "id": "RIB9l1ETs6EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_dir)"
      ],
      "metadata": {
        "id": "xBMd2htlaQhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=0) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "print(dataset_sizes)\n",
        "\n",
        "class_names = image_datasets['train'].classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "hO0gcvwFu9dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ResNet-18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the final classification layer\n",
        "for name, param in model.named_parameters():\n",
        "    if \"fc\" in name:  # Unfreeze the final classification layer\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Use all parameters\n",
        "\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "HEHKY3nUvT_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "id": "lwr2DlQWvZ-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'RCC_classification_model.pth')"
      ],
      "metadata": {
        "id": "atbnHOHVveQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification on Unseen Image\n",
        "To use the saved model to classify unseen images, you need to load the model and then apply it to the new images for inference."
      ],
      "metadata": {
        "id": "nYuk9gLkwhQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load the saved model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 1000)  # Adjust to match the original model's output units\n",
        "model.load_state_dict(torch.load('/content/RCC_classification_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Create a new model with the correct final layer\n",
        "new_model = models.resnet18(pretrained=True)\n",
        "new_model.fc = nn.Linear(new_model.fc.in_features, 2)  # Adjust to match the desired output units\n",
        "\n",
        "# Copy the weights and biases from the loaded model to the new model\n",
        "new_model.fc.weight.data = model.fc.weight.data[0:2]  # Copy only the first 2 output units\n",
        "new_model.fc.bias.data = model.fc.bias.data[0:2]"
      ],
      "metadata": {
        "id": "kCcIh09OweuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare your new image for classification. You should use the same data transformations you used during training. Here's an example of how to prepare an image for inference:"
      ],
      "metadata": {
        "id": "9mLHRlRfwlqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "test ccRCC images"
      ],
      "metadata": {
        "id": "Fb57fQO2yViL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the unseen image\n",
        "image_path = '/content/A064.jpg'  # Replace with the path to your image\n",
        "image = Image.open(image_path)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "input_tensor = preprocess(image)\n",
        "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension"
      ],
      "metadata": {
        "id": "VwLyVgzsw5bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform inference using the model:"
      ],
      "metadata": {
        "id": "94sQ0a3MxJOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Directory containing the images you want to classify\n",
        "image_dir = '/content/drive/MyDrive/โครงการFF/Images_Classification/Test'  # Replace with the actual path\n",
        "\n",
        "# List all image files in the directory\n",
        "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# Loop through the images and classify each one\n",
        "for image_path in image_files:\n",
        "    # Load and preprocess the image\n",
        "    image = Image.open(image_path)\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    input_tensor = preprocess(image)\n",
        "    input_batch = input_tensor.unsqueeze(0)\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        output = model(input_batch)\n",
        "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "    predicted_class_index = torch.argmax(probabilities).item()\n",
        "    predicted_probability = probabilities[predicted_class_index].item()\n",
        "    predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "    print(f'Image: {image_path}')\n",
        "    print(f'The predicted class is: {predicted_class_name}')\n",
        "    print(f'The predicted probability is: {predicted_probability:.4f}')\n",
        "\n",
        "    # Display the image (optional)\n",
        "    image = np.array(image)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.text(10, 10, f'Predicted: {predicted_class_name} ({predicted_probability:.2%})', fontsize=12, color='white', backgroundcolor='red')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "r4JisC3izNhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create Evaluating The Model\n",
        "\n",
        "# Evaluating the Model\n",
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "  \"\"\"Evaluates the model on a given dataloader.\n",
        "\n",
        "  Args:\n",
        "    model: The PyTorch model to evaluate.\n",
        "    dataloader: The PyTorch DataLoader for the evaluation dataset.\n",
        "    criterion: The loss function.\n",
        "    device: The device to run the evaluation on (e.g., 'cuda' or 'cpu').\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing the average loss and accuracy.\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "      running_corrects += torch.sum(preds == labels.data)\n",
        "      total_samples += inputs.size(0)\n",
        "\n",
        "  epoch_loss = running_loss / total_samples\n",
        "  epoch_acc = running_corrects.double() / total_samples\n",
        "\n",
        "  return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "val_loss, val_acc = evaluate_model(model, dataloaders['val'], criterion, device)\n",
        "print(f'Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n"
      ],
      "metadata": {
        "id": "2LuRqHvVz1x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create Evaluating The Model  Accuracy\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "  \"\"\"Evaluates the model on a given dataloader.\n",
        "\n",
        "  Args:\n",
        "    model: The PyTorch model to evaluate.\n",
        "    dataloader: The PyTorch DataLoader for the evaluation dataset.\n",
        "    criterion: The loss function.\n",
        "    device: The device to run the evaluation on (e.g., 'cuda' or 'cpu').\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing the average loss and accuracy.\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "      running_corrects += torch.sum(preds == labels.data)\n",
        "      total_samples += inputs.size(0)\n",
        "\n",
        "  epoch_loss = running_loss / total_samples\n",
        "  epoch_acc = running_corrects.double() / total_samples\n",
        "\n",
        "  return epoch_loss, epoch_acc\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "val_loss, val_acc = evaluate_model(model, dataloaders['val'], criterion, device)\n",
        "print(f'Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n"
      ],
      "metadata": {
        "id": "Zjyhsz_-0fFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_jUaz8X2zqMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Initialize lists to store true labels and predicted labels\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Iterate through the validation set\n",
        "for inputs, labels in dataloaders['val']:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    y_true.extend(labels.cpu().numpy().tolist())\n",
        "    y_pred.extend(preds.cpu().numpy().tolist())\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate and print the classification report\n",
        "report = classification_report(y_true, y_pred, target_names=class_names)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "BTLIqUIHzrIu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}